model_name : "llava-v1.6-vicuna-7b"
dataset : "infoseek_text_heavy"
sample : 'switch'

device : "cuda"
num_workers : 8

### LLM specification
max_new_tokens : 100
top_p : 0.95
repetition_penalty : 1.0
temperature : 0.0 # 0.0 means greedy decoding
length_penalty : 1.0
sampling_times : 1
retry_thres : 3
is_scored : False

output_dir : "outputs/"
model_name : "llava-1.5-7b"
dataset : "mmlu_text_heavy"
sample : 'random'

device : "cuda"
num_workers : 8

### LLM specification
max_new_tokens : 10
top_p : 0.95
repetition_penalty : 1.0
temperature : 0.0 # 0.0 means greedy decoding
length_penalty : 1.0
sampling_times : 1
retry_thres : 3
is_scored : False

output_dir : "outputs/"
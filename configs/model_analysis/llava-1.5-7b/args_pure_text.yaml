model_name : "llava-1.5-7b"
dataset : "openbookqa_pure_text"
sample : "origin"

device : "cuda"
num_workers : 8

### LLM specification
max_new_tokens : 200
top_p : 0.95
repetition_penalty : 1.0
temperature : 0.0 # 0.0 means greedy decoding
length_penalty : 1.0
sampling_times : 1
is_scored : False
retry_thres : 3

output_dir : "outputs/"
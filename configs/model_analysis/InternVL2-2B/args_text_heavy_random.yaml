model_name : "InternVL2-2B"
dataset : "mmlu_text_heavy"
batch_size : 4 #Batch Prompt
is_sub : False
sample : 'random'

device : "cuda"
num_workers : 8

### LLM specification
max_new_tokens : 20
top_p : 0.95
repetition_penalty : 1.0
temperature : 0.0 # 0.0 means greedy decoding
length_penalty : 1.0
sampling_times : 1
retry_thres : 4
# is_scored : True

output_dir : "outputs/"
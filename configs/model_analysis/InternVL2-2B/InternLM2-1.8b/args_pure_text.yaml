model_name : "InternLM2-1.8b"
dataset : "mmlu_pure_text"
sample : 'origin'

device : "cuda"
num_workers : 8

### LLM specification
max_new_tokens : 100
top_p : 0.95
repetition_penalty : 1.0
temperature : 0.0 # 0.0 means greedy decoding
length_penalty : 1.0
sampling_times : 1
retry_thres : 4
# is_scored : True

output_dir : "outputs/"
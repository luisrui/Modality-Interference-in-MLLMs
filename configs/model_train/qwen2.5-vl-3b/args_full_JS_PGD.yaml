## data
train_data_path : data/source_train_data.json
eval_data_path : data/train_LLAVA_test.json
save_dir : /data/users/your name/checkpoints/qwen2.5-vl-3b/FFT/KL_con0.001_PGD_alpha0.1_epsilon1e-2_niter2_2:2:4
image_heavy_ratio : 0.2
text_heavy_ratio : 0.2

## Log Info
wandb_project: qwen-sft
wandb_entity: 
wandb_run_name: 3b_JS_con0.001_PGD_alpha0.1_epsilon1e-3_niter2_2:2:6
wandb_run_id : "0001js001pgd3b2iter"

model : qwen2.5-vl-3b
image_min_pixels : 50176
image_max_pixels : 200704
max_length : 842
## Finetune Type
finetune_type: full
## Consistency Type
consistency_type: KL
consistency_loss_weight : 0.001
temperature : 1
## Perturb_type Type
adversarial_type: PGD
alpha : 0.1
epsilon : 0.001
pgd_steps : 2

## train model
deepspeed_config : "modules/models/deepspeed/zero3_offload.json"
seed: 2025
device : cuda
per_device_batch_size: 10
gradient_accumulation_steps : 1
epochs : 1
learning_rate : 1.0e-6

lr_scheduler_type: cosine
warmup_ratio: 0.03
adam_epsilon: 1.0e-6

weight_decay : 0.0001
logging_steps : 1
fp16 : False
bf16 : True
tf32 : True

gradient_checkpointing: True
resume_from_checkpoint: ""

## Evaluation
save_eval_steps : 600
save_total_limit : 1
val_period: 1
max_new_tokens : 100

